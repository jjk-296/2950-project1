{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "891f7b09",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "\n",
    "import seaborn\n",
    "from matplotlib import pyplot\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a8b29492",
   "metadata": {},
   "outputs": [],
   "source": [
    "import duckdb, sqlalchemy\n",
    "%load_ext sql\n",
    "\n",
    "%config SqlMagic.autopandas = True\n",
    "%config SqlMagic.feedback = False\n",
    "%config SqlMagic.displaycon = False\n",
    "\n",
    "%sql duckdb:///:memory:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a6323d22",
   "metadata": {},
   "source": [
    "**Project Title:**\n",
    "\n",
    "Did the Rise of Netflix Kill the Success of Movie Theaters?\n",
    "\n",
    "\n",
    "**Research Questions:**\n",
    "\n",
    "(1) What effect does the price of Netflix stocks have on worldwide box office revenue from 2002 to 2020?\n",
    "\n",
    "(2) What effect does the price of Netflix stocks have on domestic box office revenue from 2002 to 2020?\n",
    "\n",
    "(3) How has the price of the S&P 500 index affected domestic box office revenue from 2002 to 2020, diving into the potential effects of the overall economy on the trends of box office revenue?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4253dd25",
   "metadata": {},
   "source": [
    "**Data Collection and Cleaning:**\n",
    "\n",
    "We found three datasets for our project, with each showing the following: Netflix stock prices from 2002-2021, box office revenue (worldwide, domestic, and international) from 1940-2020 of the Top 600 well-performing movies, and S&P 500 index prices from 1927-2020. These datasets were selected because they included data (collectively) from around the time range we were looking for (early 2000’s to around current day), and because they all had extensive data on the changing prices of the respective stocks/indexes and box office revenue, as needed to properly analyze our research questions. Regarding these three raw data files, below includes a documentation of all the steps we took to turn those files into the analysis-ready datasets needed for our final project.\n",
    "\n",
    "Below is the raw data for netflix.csv, which shows Netflix stock prices from 2002 to 2021."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e9bacd45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>High</th>\n",
       "      <th>Low</th>\n",
       "      <th>Open</th>\n",
       "      <th>Close</th>\n",
       "      <th>Volume</th>\n",
       "      <th>Adj Close</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002-05-23</td>\n",
       "      <td>1.242857</td>\n",
       "      <td>1.145714</td>\n",
       "      <td>1.156429</td>\n",
       "      <td>1.196429</td>\n",
       "      <td>104790000.0</td>\n",
       "      <td>1.196429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002-05-24</td>\n",
       "      <td>1.225000</td>\n",
       "      <td>1.197143</td>\n",
       "      <td>1.214286</td>\n",
       "      <td>1.210000</td>\n",
       "      <td>11104800.0</td>\n",
       "      <td>1.210000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002-05-28</td>\n",
       "      <td>1.232143</td>\n",
       "      <td>1.157143</td>\n",
       "      <td>1.213571</td>\n",
       "      <td>1.157143</td>\n",
       "      <td>6609400.0</td>\n",
       "      <td>1.157143</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002-05-29</td>\n",
       "      <td>1.164286</td>\n",
       "      <td>1.085714</td>\n",
       "      <td>1.164286</td>\n",
       "      <td>1.103571</td>\n",
       "      <td>6757800.0</td>\n",
       "      <td>1.103571</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002-05-30</td>\n",
       "      <td>1.107857</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>1.107857</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>10154200.0</td>\n",
       "      <td>1.071429</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4876</th>\n",
       "      <td>2021-10-05</td>\n",
       "      <td>640.390015</td>\n",
       "      <td>606.890015</td>\n",
       "      <td>606.940002</td>\n",
       "      <td>634.809998</td>\n",
       "      <td>9534300.0</td>\n",
       "      <td>634.809998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4877</th>\n",
       "      <td>2021-10-06</td>\n",
       "      <td>639.869995</td>\n",
       "      <td>626.359985</td>\n",
       "      <td>628.179993</td>\n",
       "      <td>639.099976</td>\n",
       "      <td>4580400.0</td>\n",
       "      <td>639.099976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4878</th>\n",
       "      <td>2021-10-07</td>\n",
       "      <td>646.840027</td>\n",
       "      <td>630.450012</td>\n",
       "      <td>642.229980</td>\n",
       "      <td>631.849976</td>\n",
       "      <td>3556900.0</td>\n",
       "      <td>631.849976</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4879</th>\n",
       "      <td>2021-10-08</td>\n",
       "      <td>643.799988</td>\n",
       "      <td>630.859985</td>\n",
       "      <td>634.169983</td>\n",
       "      <td>632.659973</td>\n",
       "      <td>3271100.0</td>\n",
       "      <td>632.659973</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4880</th>\n",
       "      <td>2021-10-11</td>\n",
       "      <td>639.419983</td>\n",
       "      <td>626.780029</td>\n",
       "      <td>633.200012</td>\n",
       "      <td>627.039978</td>\n",
       "      <td>2861200.0</td>\n",
       "      <td>627.039978</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4881 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "            Date        High         Low        Open       Close       Volume  \\\n",
       "0     2002-05-23    1.242857    1.145714    1.156429    1.196429  104790000.0   \n",
       "1     2002-05-24    1.225000    1.197143    1.214286    1.210000   11104800.0   \n",
       "2     2002-05-28    1.232143    1.157143    1.213571    1.157143    6609400.0   \n",
       "3     2002-05-29    1.164286    1.085714    1.164286    1.103571    6757800.0   \n",
       "4     2002-05-30    1.107857    1.071429    1.107857    1.071429   10154200.0   \n",
       "...          ...         ...         ...         ...         ...          ...   \n",
       "4876  2021-10-05  640.390015  606.890015  606.940002  634.809998    9534300.0   \n",
       "4877  2021-10-06  639.869995  626.359985  628.179993  639.099976    4580400.0   \n",
       "4878  2021-10-07  646.840027  630.450012  642.229980  631.849976    3556900.0   \n",
       "4879  2021-10-08  643.799988  630.859985  634.169983  632.659973    3271100.0   \n",
       "4880  2021-10-11  639.419983  626.780029  633.200012  627.039978    2861200.0   \n",
       "\n",
       "       Adj Close  \n",
       "0       1.196429  \n",
       "1       1.210000  \n",
       "2       1.157143  \n",
       "3       1.103571  \n",
       "4       1.071429  \n",
       "...          ...  \n",
       "4876  634.809998  \n",
       "4877  639.099976  \n",
       "4878  631.849976  \n",
       "4879  632.659973  \n",
       "4880  627.039978  \n",
       "\n",
       "[4881 rows x 7 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netflix_df = pd.read_csv(\"netflix.csv\")\n",
    "netflix_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cd609b23",
   "metadata": {},
   "source": [
    "The above dataset was read and altered using pandas to convert data from “Date” column to be converted to the date type (using pandas.to_datetime) so the date data can be easily manipulated in the feature. We then created “Year” and “Month” columns to contain the respective year and month data from this new date data. “netflix_2002to2020_df” cleans the dataset by only showing data from prior to 2021 as our analyses only required data from 2002 to 2020 given the restrictions of our other datasets. We chose to only display “Date”, “Close” (price of stock when the stock market closed for that specific day), and “Year” by selecting those three columns out of the original seven columns (Date, Open, High, Low, Close, Adj Close, and Volume) using the SQL SELECT function for our final cleaned dataset for this information (“clean_netflix_df”), as shown below."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5953bba6",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning data to local variable clean_netflix_df\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Date</th>\n",
       "      <th>Close</th>\n",
       "      <th>Year</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2002-05-23</td>\n",
       "      <td>1.196429</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2002-05-24</td>\n",
       "      <td>1.210000</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2002-05-28</td>\n",
       "      <td>1.157143</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2002-05-29</td>\n",
       "      <td>1.103571</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2002-05-30</td>\n",
       "      <td>1.071429</td>\n",
       "      <td>2002</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4681</th>\n",
       "      <td>2020-12-24</td>\n",
       "      <td>513.969971</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4682</th>\n",
       "      <td>2020-12-28</td>\n",
       "      <td>519.119995</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4683</th>\n",
       "      <td>2020-12-29</td>\n",
       "      <td>530.869995</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4684</th>\n",
       "      <td>2020-12-30</td>\n",
       "      <td>524.590027</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4685</th>\n",
       "      <td>2020-12-31</td>\n",
       "      <td>540.729980</td>\n",
       "      <td>2020</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>4686 rows × 3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           Date       Close  Year\n",
       "0    2002-05-23    1.196429  2002\n",
       "1    2002-05-24    1.210000  2002\n",
       "2    2002-05-28    1.157143  2002\n",
       "3    2002-05-29    1.103571  2002\n",
       "4    2002-05-30    1.071429  2002\n",
       "...         ...         ...   ...\n",
       "4681 2020-12-24  513.969971  2020\n",
       "4682 2020-12-28  519.119995  2020\n",
       "4683 2020-12-29  530.869995  2020\n",
       "4684 2020-12-30  524.590027  2020\n",
       "4685 2020-12-31  540.729980  2020\n",
       "\n",
       "[4686 rows x 3 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "netflix_df['Date'] = pd.to_datetime(netflix_df['Date'])\n",
    "netflix_df['Year'] = netflix_df['Date'].dt.year\n",
    "netflix_df['Month'] = netflix_df['Date'].dt.month\n",
    "\n",
    "netflix_2002to2020_df = netflix_df[(netflix_df['Year']<2021)]\n",
    "netflix_2002to2020_df\n",
    "\n",
    "%sql clean_netflix_df << SELECT Date, Close, Year FROM netflix_2002to2020_df\n",
    "\n",
    "clean_netflix_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e620698",
   "metadata": {},
   "source": [
    "Below is the raw data for worldwideboxoffice.csv, which shows box office revenue from 1940 to 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a80145f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Year</th>\n",
       "      <th>Movie</th>\n",
       "      <th>WorldwideBox Office</th>\n",
       "      <th>DomesticBox Office</th>\n",
       "      <th>InternationalBox Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>$2,845,899,541</td>\n",
       "      <td>$760,507,625</td>\n",
       "      <td>$2,085,391,916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>Avengers: Endgame</td>\n",
       "      <td>$2,797,800,564</td>\n",
       "      <td>$858,373,000</td>\n",
       "      <td>$1,939,427,564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1997</td>\n",
       "      <td>Titanic</td>\n",
       "      <td>$2,207,986,545</td>\n",
       "      <td>$659,363,944</td>\n",
       "      <td>$1,548,622,601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>Star Wars Ep. VII: The Force Awakens</td>\n",
       "      <td>$2,064,615,817</td>\n",
       "      <td>$936,662,225</td>\n",
       "      <td>$1,127,953,592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>Avengers: Infinity War</td>\n",
       "      <td>$2,044,540,523</td>\n",
       "      <td>$678,815,482</td>\n",
       "      <td>$1,365,725,041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>590</th>\n",
       "      <td>596</td>\n",
       "      <td>2010</td>\n",
       "      <td>Knight and Day</td>\n",
       "      <td>$258,751,370</td>\n",
       "      <td>$76,423,035</td>\n",
       "      <td>$182,328,335</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>591</th>\n",
       "      <td>597</td>\n",
       "      <td>1985</td>\n",
       "      <td>Out of Africa</td>\n",
       "      <td>$258,210,860</td>\n",
       "      <td>$79,096,868</td>\n",
       "      <td>$179,113,992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>592</th>\n",
       "      <td>598</td>\n",
       "      <td>2011</td>\n",
       "      <td>Super 8</td>\n",
       "      <td>$257,972,745</td>\n",
       "      <td>$127,004,179</td>\n",
       "      <td>$130,968,566</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>593</th>\n",
       "      <td>599</td>\n",
       "      <td>2013</td>\n",
       "      <td>American Hustle</td>\n",
       "      <td>$257,858,943</td>\n",
       "      <td>$150,098,456</td>\n",
       "      <td>$107,760,487</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>594</th>\n",
       "      <td>600</td>\n",
       "      <td>2000</td>\n",
       "      <td>Erin Brockovich</td>\n",
       "      <td>$257,805,243</td>\n",
       "      <td>$125,548,685</td>\n",
       "      <td>$132,256,558</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>595 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rank  Year                                 Movie WorldwideBox Office  \\\n",
       "0       1  2009                                Avatar      $2,845,899,541   \n",
       "1       2  2019                     Avengers: Endgame      $2,797,800,564   \n",
       "2       3  1997                               Titanic      $2,207,986,545   \n",
       "3       4  2015  Star Wars Ep. VII: The Force Awakens      $2,064,615,817   \n",
       "4       5  2018                Avengers: Infinity War      $2,044,540,523   \n",
       "..    ...   ...                                   ...                 ...   \n",
       "590   596  2010                        Knight and Day        $258,751,370   \n",
       "591   597  1985                         Out of Africa        $258,210,860   \n",
       "592   598  2011                               Super 8        $257,972,745   \n",
       "593   599  2013                       American Hustle        $257,858,943   \n",
       "594   600  2000                       Erin Brockovich        $257,805,243   \n",
       "\n",
       "    DomesticBox Office InternationalBox Office  \n",
       "0         $760,507,625          $2,085,391,916  \n",
       "1         $858,373,000          $1,939,427,564  \n",
       "2         $659,363,944          $1,548,622,601  \n",
       "3         $936,662,225          $1,127,953,592  \n",
       "4         $678,815,482          $1,365,725,041  \n",
       "..                 ...                     ...  \n",
       "590        $76,423,035            $182,328,335  \n",
       "591        $79,096,868            $179,113,992  \n",
       "592       $127,004,179            $130,968,566  \n",
       "593       $150,098,456            $107,760,487  \n",
       "594       $125,548,685            $132,256,558  \n",
       "\n",
       "[595 rows x 6 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxoffice_df = pd.read_csv(\"worldwideboxoffice.csv\")\n",
    "boxoffice_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "153d8371",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Year</th>\n",
       "      <th>Movie</th>\n",
       "      <th>WorldwideBox Office</th>\n",
       "      <th>DomesticBox Office</th>\n",
       "      <th>InternationalBox Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>Avatar</td>\n",
       "      <td>$2,845,899,541</td>\n",
       "      <td>$760,507,625</td>\n",
       "      <td>$2,085,391,916</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>Avengers: Endgame</td>\n",
       "      <td>$2,797,800,564</td>\n",
       "      <td>$858,373,000</td>\n",
       "      <td>$1,939,427,564</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1997</td>\n",
       "      <td>Titanic</td>\n",
       "      <td>$2,207,986,545</td>\n",
       "      <td>$659,363,944</td>\n",
       "      <td>$1,548,622,601</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>Star Wars Ep. VII: The Force Awakens</td>\n",
       "      <td>$2,064,615,817</td>\n",
       "      <td>$936,662,225</td>\n",
       "      <td>$1,127,953,592</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>Avengers: Infinity War</td>\n",
       "      <td>$2,044,540,523</td>\n",
       "      <td>$678,815,482</td>\n",
       "      <td>$1,365,725,041</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "      <td>Jurassic World</td>\n",
       "      <td>$1,669,979,967</td>\n",
       "      <td>$652,306,625</td>\n",
       "      <td>$1,017,673,342</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>2019</td>\n",
       "      <td>The Lion King</td>\n",
       "      <td>$1,654,367,425</td>\n",
       "      <td>$543,638,043</td>\n",
       "      <td>$1,110,729,382</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>2015</td>\n",
       "      <td>Furious 7</td>\n",
       "      <td>$1,516,881,526</td>\n",
       "      <td>$353,007,020</td>\n",
       "      <td>$1,163,874,506</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>2012</td>\n",
       "      <td>The Avengers</td>\n",
       "      <td>$1,515,100,211</td>\n",
       "      <td>$623,357,910</td>\n",
       "      <td>$891,742,301</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>2019</td>\n",
       "      <td>Frozen II</td>\n",
       "      <td>$1,446,925,396</td>\n",
       "      <td>$477,373,578</td>\n",
       "      <td>$969,551,818</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Rank  Year                                 Movie WorldwideBox Office  \\\n",
       "0     1  2009                                Avatar      $2,845,899,541   \n",
       "1     2  2019                     Avengers: Endgame      $2,797,800,564   \n",
       "2     3  1997                               Titanic      $2,207,986,545   \n",
       "3     4  2015  Star Wars Ep. VII: The Force Awakens      $2,064,615,817   \n",
       "4     5  2018                Avengers: Infinity War      $2,044,540,523   \n",
       "5     6  2015                        Jurassic World      $1,669,979,967   \n",
       "6     7  2019                         The Lion King      $1,654,367,425   \n",
       "7     8  2015                             Furious 7      $1,516,881,526   \n",
       "8     9  2012                          The Avengers      $1,515,100,211   \n",
       "9    10  2019                             Frozen II      $1,446,925,396   \n",
       "\n",
       "  DomesticBox Office InternationalBox Office  \n",
       "0       $760,507,625          $2,085,391,916  \n",
       "1       $858,373,000          $1,939,427,564  \n",
       "2       $659,363,944          $1,548,622,601  \n",
       "3       $936,662,225          $1,127,953,592  \n",
       "4       $678,815,482          $1,365,725,041  \n",
       "5       $652,306,625          $1,017,673,342  \n",
       "6       $543,638,043          $1,110,729,382  \n",
       "7       $353,007,020          $1,163,874,506  \n",
       "8       $623,357,910            $891,742,301  \n",
       "9       $477,373,578            $969,551,818  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "boxoffice_df.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5bece1f",
   "metadata": {},
   "source": [
    "For the above dataset, we used pandas to only show information from after the year 2001 (starting from 2002) as that was the time range we’ll be examining for our analyses and used the SQL SELECT function to only select the “Rank”, “Year”, “WorldwideBox Office” and “DomesticBox Office” columns’ data, as shown below. This is because we were not planning on looking at any relations pertaining to the “InternationalBox Office” column as it was not applicable to our research questions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ea5067f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Returning data to local variable clean_box_df\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/4s/8m7ssht135535p0jljzkdvvm0000gn/T/ipykernel_38515/1305087542.py:2: UserWarning: Boolean Series key will be reindexed to match DataFrame index.\n",
      "  from2002_to2020_boxofficehit_df = from2002_to2020_boxofficehit_df[(boxoffice_df['Year']<2021)]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Rank</th>\n",
       "      <th>Year</th>\n",
       "      <th>WorldwideBox Office</th>\n",
       "      <th>DomesticBox Office</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>2009</td>\n",
       "      <td>$2,845,899,541</td>\n",
       "      <td>$760,507,625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>2019</td>\n",
       "      <td>$2,797,800,564</td>\n",
       "      <td>$858,373,000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>4</td>\n",
       "      <td>2015</td>\n",
       "      <td>$2,064,615,817</td>\n",
       "      <td>$936,662,225</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5</td>\n",
       "      <td>2018</td>\n",
       "      <td>$2,044,540,523</td>\n",
       "      <td>$678,815,482</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>6</td>\n",
       "      <td>2015</td>\n",
       "      <td>$1,669,979,967</td>\n",
       "      <td>$652,306,625</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>443</th>\n",
       "      <td>593</td>\n",
       "      <td>2013</td>\n",
       "      <td>$260,002,115</td>\n",
       "      <td>$89,302,115</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>444</th>\n",
       "      <td>595</td>\n",
       "      <td>2017</td>\n",
       "      <td>$259,238,971</td>\n",
       "      <td>$92,054,159</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>445</th>\n",
       "      <td>596</td>\n",
       "      <td>2010</td>\n",
       "      <td>$258,751,370</td>\n",
       "      <td>$76,423,035</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>446</th>\n",
       "      <td>598</td>\n",
       "      <td>2011</td>\n",
       "      <td>$257,972,745</td>\n",
       "      <td>$127,004,179</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>447</th>\n",
       "      <td>599</td>\n",
       "      <td>2013</td>\n",
       "      <td>$257,858,943</td>\n",
       "      <td>$150,098,456</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>448 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Rank  Year WorldwideBox Office DomesticBox Office\n",
       "0       1  2009      $2,845,899,541       $760,507,625\n",
       "1       2  2019      $2,797,800,564       $858,373,000\n",
       "2       4  2015      $2,064,615,817       $936,662,225\n",
       "3       5  2018      $2,044,540,523       $678,815,482\n",
       "4       6  2015      $1,669,979,967       $652,306,625\n",
       "..    ...   ...                 ...                ...\n",
       "443   593  2013        $260,002,115        $89,302,115\n",
       "444   595  2017        $259,238,971        $92,054,159\n",
       "445   596  2010        $258,751,370        $76,423,035\n",
       "446   598  2011        $257,972,745       $127,004,179\n",
       "447   599  2013        $257,858,943       $150,098,456\n",
       "\n",
       "[448 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from2002_to2020_boxofficehit_df = boxoffice_df[(boxoffice_df['Year']>2001)]\n",
    "from2002_to2020_boxofficehit_df = from2002_to2020_boxofficehit_df[(boxoffice_df['Year']<2021)]\n",
    "\n",
    "%sql clean_box_df << SELECT Rank, Year, \"WorldwideBox Office\", \"DomesticBox Office\" FROM from2002_to2020_boxofficehit_df \n",
    "\n",
    "clean_box_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7530ee8d",
   "metadata": {},
   "source": [
    "Below is the raw data for sp500.csv, which shows S&P 500 index price data from 1927 to 2020."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "865079cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: 'sp500.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Input \u001b[0;32mIn [10]\u001b[0m, in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0m sp_500_df \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43msp500.csv\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m sp_500_df\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/info2950/lib/python3.9/site-packages/pandas/util/_decorators.py:311\u001b[0m, in \u001b[0;36mdeprecate_nonkeyword_arguments.<locals>.decorate.<locals>.wrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    305\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(args) \u001b[38;5;241m>\u001b[39m num_allow_args:\n\u001b[1;32m    306\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m    307\u001b[0m         msg\u001b[38;5;241m.\u001b[39mformat(arguments\u001b[38;5;241m=\u001b[39marguments),\n\u001b[1;32m    308\u001b[0m         \u001b[38;5;167;01mFutureWarning\u001b[39;00m,\n\u001b[1;32m    309\u001b[0m         stacklevel\u001b[38;5;241m=\u001b[39mstacklevel,\n\u001b[1;32m    310\u001b[0m     )\n\u001b[0;32m--> 311\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/info2950/lib/python3.9/site-packages/pandas/io/parsers/readers.py:680\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, squeeze, prefix, mangle_dupe_cols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, error_bad_lines, warn_bad_lines, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options)\u001b[0m\n\u001b[1;32m    665\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m    666\u001b[0m     dialect,\n\u001b[1;32m    667\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    676\u001b[0m     defaults\u001b[38;5;241m=\u001b[39m{\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdelimiter\u001b[39m\u001b[38;5;124m\"\u001b[39m: \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m,\u001b[39m\u001b[38;5;124m\"\u001b[39m},\n\u001b[1;32m    677\u001b[0m )\n\u001b[1;32m    678\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m--> 680\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/info2950/lib/python3.9/site-packages/pandas/io/parsers/readers.py:575\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    572\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    574\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 575\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    578\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/info2950/lib/python3.9/site-packages/pandas/io/parsers/readers.py:934\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m    931\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m    933\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m--> 934\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/info2950/lib/python3.9/site-packages/pandas/io/parsers/readers.py:1218\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1214\u001b[0m     mode \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1215\u001b[0m \u001b[38;5;66;03m# error: No overload variant of \"get_handle\" matches argument types\u001b[39;00m\n\u001b[1;32m   1216\u001b[0m \u001b[38;5;66;03m# \"Union[str, PathLike[str], ReadCsvBuffer[bytes], ReadCsvBuffer[str]]\"\u001b[39;00m\n\u001b[1;32m   1217\u001b[0m \u001b[38;5;66;03m# , \"str\", \"bool\", \"Any\", \"Any\", \"Any\", \"Any\", \"Any\"\u001b[39;00m\n\u001b[0;32m-> 1218\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# type: ignore[call-overload]\u001b[39;49;00m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1229\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/Applications/anaconda3/envs/info2950/lib/python3.9/site-packages/pandas/io/common.py:786\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    781\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    782\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    783\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    784\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    785\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 786\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    787\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    788\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    789\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    790\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    791\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    792\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    793\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    794\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    795\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'sp500.csv'"
     ]
    }
   ],
   "source": [
    "sp_500_df = pd.read_csv(\"sp500.csv\")\n",
    "sp_500_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fc8dedc4",
   "metadata": {},
   "source": [
    "For the above dataset, we used the pandas to_datetime method to convert data from the “Date” column to the date type for easier future manipulation of this data. We assigned new “Year” and “Month” columns for the respective year and month data, then used pandas to only show data from after the year 2001 (starting from 2002) as that fits the time interval we will examine for our analyses. We then cleaned our dataset using the SQL SELECT function to only select “Date”, “Close” and “Year” in the cleaned dataset as these are the only values we will be observing, as shown below. We chose to select “Close” (which is how much the S&P 500 index price was at the close of that specific stock market day’s closing) among “Open”, “High”, and “Low” as we believe it is relatively representative of the overall performance of the index price for any given day."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf4c14c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sp_500_df['Date'] = pd.to_datetime(sp_500_df['Date'])\n",
    "sp_500_df['Year'] = sp_500_df['Date'].dt.year\n",
    "sp_500_df['Month'] = sp_500_df['Date'].dt.month\n",
    "\n",
    "sp_500_2002to2020_df = sp_500_df[(sp_500_df['Year']>2001)]\n",
    "sp_500_2002to2020_df\n",
    "%sql clean_sp500_df << SELECT Date, Close, Year FROM sp_500_2002to2020_df\n",
    "\n",
    "clean_sp500_df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "97a92c75",
   "metadata": {},
   "source": [
    "**Data Description:**\n",
    "\n",
    "Netflix Daily Stock Prices: The dataset we selected is about Netflix’s daily stock prices from 2002 to 2021. The columns of the dataset include the date, low, high, open, close, volume, and adj close for the Netflix stocks. While date, high, low are self explanatory, the open column is  the starting period of trading on a securities exchange or organized over-the-counter market, the close is the last price at which a stock trades during a regular trading session. The volume is an indicator of market strength, as rising markets on increasing volume are typically, and the adj closing price amends a stock's closing price to reflect that stock's value after accounting for any. There are 4,881 instances in total, and we decided to focus on one column of the data, which is the close price of the stocks and used data from 2002 to 2020, which is 4,686 instances, because the other dataset we are using has data until 2020. The data most likely contains all instances and is not a sample, but there may be some missing instances in the middle. All the data is directly related to Netflix’s stocks and is self-contained. There is no confidential or offensive information in this data as it does not pertain to a specific subgroup and the individual instances are not people but are prices. Past uses of the data include predicting future stock prices of Netflix and mostly using it for research about economics, stock markets, and finance. \n",
    "\n",
    "Box Office Revenue: The data shows international, domestic, worldwide box office revenue for the top 600 movies of all time. (Note: Box office revenue doesn’t include DVD sales or streaming.) The columns include the title of the movies, the release year, and the international, domestic, and worldwide box office revenues. The domestic box office revenue will be US revenue, international would be revenue from countries outside of the US, and worldwide would be the total revenue globally. There are 600 instances in total as the dataset collects data about the top 600 movies with the highest revenue from 1940-2020. The data is not a random sample, but is a sample of the top 600 movies, and is comprehensive without missing data but it does not contain data about movies with lower revenue than those in the top-performing list of 600. We decided to focus on data instances from 2002 to 2020, which would be 454 instances, because the Netflix dataset starts from 2002 and our S&P 500 dataset collected data until 2020. All the data is directly related to the box office revenue and is self-contained. There is no confidential or offensive information in this data as it does not pertain to a specific subgroup and the individual instances are not people but are revenues. Past uses of the data include… \n",
    "\n",
    "S&P 500: The S&P 500 data is a stock market index tracking the stock performance of 500 large companies listed on stock exchanges in the United States. We decided to use this data in order to verify if the changes in box office revenue prices were actually affected/caused by the Netflix stock prices or if they were just showing a correlation. The columns of this dataset include the Date, Open, High, Low, Close, Adj Close, and Volume like the Netflix dataset. We decided to use the data from 2002 to 2020 only, and that would be 4,745 instances out of 23,324. The data most likely contains all instances and is not a sample, but there may be some missing instances in the middle. All the data is directly related to the stock market prices of the top 500 companies in the US and is self-contained. There is no confidential or offensive information in this data as it does not pertain to a specific subgroup and the individual instances are not people but are prices. Like the Netflix dataset, past uses of the data include predicting future stock prices and economic trends of the United States, and research in areas such as business, economics, stock markets, government, and finance.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8db4c1",
   "metadata": {},
   "source": [
    "**Data Limitations:**\n",
    "\n",
    "One limitation of our data is that we chose to examine correlations between worldwide and domestic box office and Netflix stock prices in an effort to analyze the effect of streaming services on box office success, but not every country uses Netflix as a primary streaming service. While Netflix is the largest streaming company in the world (~225 million subscribers worldwide), there are a number of other prominent streaming services that will not have been accounted for, such as HBO, Hulu, and Disney+. Thus, only accounting for Netflix in our data, while likely representing the overall impact of streaming services on box office successes in the general sense, may not entirely properly represent the impact of streaming services as a whole. Moreover, our first two research questions observe data from the Netflix stock price and box office revenue datasets without accounting for inflation as due to it, stock prices would see a general increase over the years. However, in order to account for this and deeper dive into the effect of the overall economy on box office revenue and the overall status of movie theaters’ success, our third research question attempts to explore this exact relationship so that our readers will ideally have more accurate context of the economic status of the U.S. so that they can better understand the data analyzed for our second research question. Furthermore, our box office revenue dataset only lists out data for the top 600 best-performing films from 1950 to 2020 and thus doesn’t include data for all films in this time period, meaning this dataset doesn’t contain collective box office revenue for all films and therefore isn’t perfectly representative of the entire movie theater or box office revenue. Furthermore, given that stock prices were recorded by day whereas box office revenue was accumulated for each movie per their release year, we will have to aggregate the data to match one another for any meaningful analysis."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90ecae68",
   "metadata": {},
   "source": [
    "**Exploratory Data Analysis:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a4339351",
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.lineplot(data = clean_netflix_df, x = \"Year\", y = \"High\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806f52ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.boxplot(data = clean_box_df, x = \"Year\", y = \"Rank\")\n",
    "plt.xticks(rotation =60)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e9d8c47",
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.lineplot(data = clean_box_df, x = \"Year\", y = \"Rank\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "949c752d",
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.lineplot(data = clean_sp500_df, x = \"Year\", y = \"Close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b090d0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "seaborn.lineplot(data = clean_netflix_df, x = \"Year\", y = \"Close\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e713fb76",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "%sql clean_box_avgrank_df << SELECT AVG(Rank) AS avgrank, Year FROM clean_box_df GROUP BY Year ORDER BY Year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "82506bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "%sql clean_netflix_avgclose_df << SELECT AVG(Close) AS avgclose, Year FROM clean_netflix_df GROUP BY Year ORDER BY Year\n",
    "clean_netflix_avgclose_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fcc44492",
   "metadata": {},
   "outputs": [],
   "source": [
    "clean_box_avgrank_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66359906",
   "metadata": {},
   "outputs": [],
   "source": [
    "boxrank_netflixclose_df = pd.concat([clean_box_avgrank_df, clean_netflix_avgclose_df], axis=1, join='inner')\n",
    "display(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d8730d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(boxrank_netflixclose_df['avgrank'])\n",
    "plt.plot(boxrank_netflixclose_df['avgclose'])\n",
    "plt.ylabel('avg', fontsize=14)\n",
    "plt.xlabel('Year since 2002', fontsize=14)\n",
    "plt.title('Comparing Netflix avg stock price and avg Box office rank', fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9917e86a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473ae69a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eddea853",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e1289ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a23007b7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "a7d8d332",
   "metadata": {},
   "source": [
    "**Questions for Reviewers:**\n",
    "\n",
    "How can we improve on the complexity and clarity of our research questions?\n",
    "How should we go about saving our new cleaned datasets in our GitHub repository, or is it acceptable to clean the data from within our .ipynb files and simply keep the raw data files there?\n",
    "Suggestions on other kinds of data visualizations we can explore for our data analysis?\n",
    "How thorough and on-track are our analyses of the analyzed trends?\n",
    "What are some ways we can tangibly strengthen our exploratory data analysis?\n",
    "What are some other clear limitations of our datasets aside from the ones already listed?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9653fe",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "vscode": {
   "interpreter": {
    "hash": "cd78fef2128015050713e82ca51c6520b11aee7c9ee8df750520bbbc7384cbaa"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
